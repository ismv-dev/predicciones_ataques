{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddefc9ca-2eea-4f34-a94a-50289a07880d",
   "metadata": {},
   "source": [
    "<h1>Importes necesarios</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e619c74-4a76-49cd-b717-ee0d69a9fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install scikit-learn\\n!pip install pandas\\n!pip install numpy\\n!pip install joblib\\n!pip install tensorflow\\n!pip install keras'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install joblib\n",
    "!pip install tensorflow\n",
    "!pip install keras'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fccd52-b911-44fe-ae4a-e8507dd847f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google.protobuf.pyext._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google.protobuf.pyext._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22d563-bd62-4265-a073-bc2745504b05",
   "metadata": {},
   "source": [
    "<h1>Pipeline de limpieza de datos y preparación</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f595bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Limpiar(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.map(lambda x: x.strip().strip(\"'\").strip() if isinstance(x, str) else x).iloc[:, 1:]\n",
    "\n",
    "class CodificarCategoricos(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.dummy_columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        dummies = pd.get_dummies(X.iloc[:, 1:4])\n",
    "        self.dummy_columns = dummies.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        dummies = pd.get_dummies(X.iloc[:, 1:4])\n",
    "        dummies = dummies.reindex(columns=self.dummy_columns, fill_value=0)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        drop = list(X.columns[1:4])\n",
    "        y = None\n",
    "        if X.shape[1] > 41:\n",
    "            y = X.iloc[:, 41].map({'Normal': 0, 'Ataque': 1})\n",
    "            drop.append(X.columns[41])\n",
    "        X = X.drop(columns=drop).astype('float')\n",
    "        X_encoded = pd.concat([X, dummies, y], axis=1)\n",
    "        X_encoded.columns.values[-1] = 'y'\n",
    "        return X_encoded\n",
    "\n",
    "class ImputarNulos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.fillna(X.mean())\n",
    "\n",
    "class Escalar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X), columns=X.columns, index=X.index)\n",
    "        return X_scaled\n",
    "\n",
    "class Reducir(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.pca = PCA(n_components=5)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if X.columns[-1] == 'y':\n",
    "            X = X.drop(columns=X.columns[-1]).astype('float')\n",
    "        self.pca.fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        y = None\n",
    "        if X.columns[-1] == 'y':\n",
    "            y = X.iloc[:,-1]\n",
    "            X = X.drop(columns=X.columns[-1]).astype('float')\n",
    "        X_reduced = pd.DataFrame(self.pca.transform(X), index=X.index)\n",
    "        return pd.concat([X_reduced, y], axis=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('limpiar', Limpiar()),\n",
    "    ('codificar_categoricos', CodificarCategoricos()),\n",
    "    ('imputar_nulos', ImputarNulos()),\n",
    "    ('escalar', Escalar()),\n",
    "    ('reducir', Reducir()),\n",
    "])\n",
    "joblib.dump(pipeline, \"pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d148e48-c3e8-478e-82a2-1943c6e7b7f5",
   "metadata": {},
   "source": [
    "<h1>Ejecutar el pipeline sobre el set de datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28a733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.04 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "df = pd.read_csv(\"muestra_ataques.csv\", header=None)\n",
    "df = pipeline.fit_transform(df)\n",
    "joblib.dump(pipeline, \"pipeline.pkl\")\n",
    "datos = df.to_numpy()\n",
    "\n",
    "y = datos[:,-1]\n",
    "X = datos[:,:-1]\n",
    "\n",
    "X, y = np.array(X, dtype='float64'), np.array(y, dtype='int')\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bb6a1-47b4-4c0b-8bbe-bdf1a80d22f8",
   "metadata": {},
   "source": [
    "<h1>Definir set de entrenamiento del 80% y set de prueba del 20%</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1237d7c2-1543-4ce6-88b1-a2d7fddc3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "modelos=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b20a9c-632a-4bb7-8c67-0a1a8e7eec5c",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de modelo de regresión logistica</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e979a3e-a125-4c22-946f-b18b041aa462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.00 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=123\n",
    ")\n",
    "modelo = modelo.fit(X_train, y_train)\n",
    "modelos.append([modelo, 'lr'])\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75b2b1-4187-4dfa-911f-d645b24d9309",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para árbol de clasificación con validación cruzada de 4 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4fa71e-f7e4-492f-8bb9-44e3c174dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.31 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = DecisionTreeClassifier(random_state=1234)\n",
    "parametros = {'max_depth': [1,2,3,4,5,6,7,8,9,10,11,12,None],\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'min_samples_split': [2,3,4,5,6,7,8],\n",
    "              'min_samples_leaf': [1,2,3,4,5,6],\n",
    "              'ccp_alpha': [0,0.0001,0.001,0.01,0.1,1]\n",
    "             }\n",
    "random_search = RandomizedSearchCV(modelo, parametros, cv=4, random_state=123, n_jobs=-1, n_iter=500)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03ff50-387a-4be6-86c5-77be51797728",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de modelo de árbol de decision con mejores hiperparámetros</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ca97c6-a8bd-4523-8264-1c39e5e21bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.00 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = DecisionTreeClassifier(max_depth = random_search.best_params_['max_depth'],\n",
    "                             criterion = random_search.best_params_['criterion'],\n",
    "                             min_samples_split = random_search.best_params_['min_samples_split'],\n",
    "                             min_samples_leaf = random_search.best_params_['min_samples_leaf'],\n",
    "                             ccp_alpha =random_search.best_params_['ccp_alpha'])\n",
    "modelo = modelo.fit(X_train, y_train)\n",
    "modelos.append([modelo, 'clf'])\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186c102-29e9-4c02-9bc0-2fa4627eca97",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para modelo K vecinos cercanos con validación cruzada de 4 carpetas sobre una parte del set de entrenamiento usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc665ab-4bfb-47dd-aca2-d0efc62256e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  2.84 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = KNeighborsClassifier()\n",
    "parametros = {'n_neighbors': range(1,60),\n",
    "              'p': [a/10 for a in range(10,30,5)],\n",
    "              'weights': ['distance', 'uniform'],\n",
    "             }\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=4, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77e97b-8e00-4add-9e45-dbc87930032c",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento para modelo de K vecinos cercanos con los mejores hiperparámetros</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd64ba5b-4ce1-4069-887c-2853cdd7355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.00 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = KNeighborsClassifier(n_neighbors=grid_search.best_params_['n_neighbors'],\n",
    "              p=grid_search.best_params_['p'],\n",
    "              weights=grid_search.best_params_['weights'])\n",
    "\n",
    "modelo = modelo.fit(X_train, y_train)\n",
    "modelos.append([modelo, 'knn'])\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c564c34-f827-4b2b-acca-2d30ad38b9be",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para máquina de soporte vectorial con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8d6b2a2-2f74-4bdb-828f-cd9733a80931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.94 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "parametros = {'coef0': [75,100,125],\n",
    "              'degree': [2,3,4],\n",
    "              'kernel': ['linear','poly','rbf']\n",
    "             }\n",
    "modelo = svm.SVC()\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=4, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5513dd-fde0-4005-8e6b-3c8d1050b898",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de modelo máquina de soporte vectorial con mejores hiperparámetros</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b772608-0b0c-4114-b8e0-5ff5e6025011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.25 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "modelo = svm.SVC(coef0=grid_search.best_params_['coef0'],\n",
    "              degree=grid_search.best_params_['degree'],\n",
    "              kernel=grid_search.best_params_['kernel'])\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "modelos.append([modelo, 'svm'])\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af474f82-fcda-469e-9dfd-558362693583",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de modelo de redes neuronales con parte del set de entrenamiento, con una capa de entrada, dos capas ocultas y una capa de salida con una funcion de activacion sigmoidal y una funcion de perdida de entropia binaria cruzada</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2bad633-de5d-41dd-993a-6c9cf3e62430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion:  0.49 minutos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "seed_value= 1234\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "modelo = Sequential()\n",
    "modelo.add(Input(shape=(X_train.shape[1],)))\n",
    "modelo.add(Dense(units=64, activation='relu'))\n",
    "modelo.add(Dense(units=32, activation='relu'))\n",
    "modelo.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.5)\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "modelo.compile(loss='binary_crossentropy', optimizer=opt, metrics=['recall'])\n",
    "\n",
    "modelo.fit(X_train, y_train, epochs=100,\n",
    "          batch_size=1000,\n",
    "          verbose = 0)\n",
    "\n",
    "modelos.append([modelo, 'ann'])\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3130bb-7a98-4e2f-aa72-a20a1efc17d3",
   "metadata": {},
   "source": [
    "<h1>Evaluación de los modelos con el set de entrenamiento según métricas exactitud, precisión, recall y f1-score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efdfc60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------  lr  -----------\n",
      "Tiempo de ejecucion:  0.00 minutos\n",
      "\n",
      "Exactitud: 0.9477670666928979\n",
      "\n",
      "Matriz de confusion: [[19018  1056]\n",
      " [    6   252]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     20074\n",
      "           1       0.19      0.98      0.32       258\n",
      "\n",
      "    accuracy                           0.95     20332\n",
      "   macro avg       0.60      0.96      0.65     20332\n",
      "weighted avg       0.99      0.95      0.96     20332\n",
      "\n",
      "\n",
      "-----------  clf  -----------\n",
      "Tiempo de ejecucion:  0.00 minutos\n",
      "\n",
      "Exactitud: 0.9982785756443046\n",
      "\n",
      "Matriz de confusion: [[20067     7]\n",
      " [   28   230]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20074\n",
      "           1       0.97      0.89      0.93       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.98      0.95      0.96     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n",
      "\n",
      "-----------  knn  -----------\n",
      "Tiempo de ejecucion:  0.00 minutos\n",
      "\n",
      "Exactitud: 0.9993114302577218\n",
      "\n",
      "Matriz de confusion: [[20069     5]\n",
      " [    9   249]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20074\n",
      "           1       0.98      0.97      0.97       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.99      0.98      0.99     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n",
      "\n",
      "-----------  svm  -----------\n",
      "Tiempo de ejecucion:  0.00 minutos\n",
      "\n",
      "Exactitud: 0.9969014361597481\n",
      "\n",
      "Matriz de confusion: [[20057    17]\n",
      " [   46   212]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20074\n",
      "           1       0.93      0.82      0.87       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.96      0.91      0.93     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n",
      "\n",
      "-----------  ann  -----------\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step\n",
      "Tiempo de ejecucion:  0.01 minutos\n",
      "\n",
      "Exactitud: 0.9959177650993508\n",
      "\n",
      "Matriz de confusion: [[20044    30]\n",
      " [   53   205]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20074\n",
      "           1       0.87      0.79      0.83       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.93      0.90      0.91     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modelo in modelos:\n",
    "    print('\\n-----------  '+modelo[1]+'  -----------')\n",
    "    inicio = time.time()\n",
    "    y_hat = (modelo[0].predict(X_test)>=0.5).astype(int)\n",
    "    print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "    print('\\nExactitud:', accuracy_score(y_test,y_hat))\n",
    "    print('\\nMatriz de confusion:', confusion_matrix(y_test, y_hat))\n",
    "    print('\\nReporte:\\n', classification_report(y_test, y_hat))\n",
    "    modelo.append(f1_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8cce5-8225-4851-85ce-b5e054cb1086",
   "metadata": {},
   "source": [
    "<h1>Despliegue y entrenamiento extra del mejor modelo según f1-score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91e38aec-e966-4ff6-8f87-5fe869eaa0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: knn\n",
      "F1-Score: 0.97265625\n"
     ]
    }
   ],
   "source": [
    "modelos=sorted(modelos, key=lambda x: x[-1], reverse=True)\n",
    "modelos[0][0] = modelos[0][0].fit(X_test, y_test)\n",
    "if (modelos[0][1] == 'ann'):\n",
    "    modelos[0][0].save(\"modelo.keras\")\n",
    "else:\n",
    "    joblib.dump(modelos[0][0], \"modelo.pkl\")\n",
    "print(f'Mejor modelo: {modelos[0][1]}')\n",
    "print(f'F1-Score: {modelos[0][2]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
